# ItemSets Practicum
This project will produce high-confidence inferences from the per-user itemsets provided
by the electronics store orders files provided along with this description.  
These files provide data on customers and purchased products.  You'll analyze
the data to find product purchase patterns.  It has several phases,
roughly reflecting the typical phases of a professional data analysis project.

## Phase 1 Review the data and make a plan
The provided files do not provide a direct mapping from purchases (transactions)
to sets of purchased product ids (items).  And not all rows are even useful to 
an itemset analysis seeking association rules.  You must glean from this data
a clean set of useful transactions.

A good data science process includes a careful review of the data, and a plan to
"clean" it in appropriate ways.  Review the provided csv files -- you may find
the Orders100.csv an easier starting point.  Determine which rows are 
actually useful.

Then, determine what final dataframe structure will best 
support a Eclat/dEclat algorithm. 

Create a short file Analysis.md in that subdirectory summarizing your results.  
Submit this md file and the corresponding HTML file to the relevant Canvas 
assignment for my approval before proceeding.  Write no code in this phase!

(Learn MD if you haven't already.  It's an excellent format for Git repository 
documentation since it merges well.  Edit your Markdown in VSCode, using the
Markdown+Math plugin.)

### Phase 2 Write code to implement your plan
Write a program Analyze.py that uses Pandas to input a given Orders CSV file (first 
commandline argument) and prints basic stats on the products, orders and customers.  
It then performs the cleaning and reorganization you planned in the prior step, 
producing a Pandas Dataframe as its final product.  It writes the DataFrame to
the a specified Pickle output file (second commandline argument), and then reads
it back in and prints it, to confirm successful file save. 

A few important points:
 * Do not write any loops or if-statements in this code.  Use Pandas Dataframes,
 groupBy, etc to do the work.  My implementation is **10 lines long**.  Yours
 should be comparably brief.
 * You may choose any file format you like, but be sure it loads and saves 
 quickly with the full dataset.
 * Your cleaning may include dropping some users as irrelevant to the 
 creation of association rules.  Make such dropping optional, by allowing 
 a final "all" flag that generates all transactions, even those with just one item.

Sample run.  Yours may look different.
```
clint@rifle:~/DataScience/Projects/Sandbox$python3 Analyze.py Orders10000.csv Orders10000.pck
Reading Orders10000.csv
Number of products: 3186
Number of orders: 8260
Number of customers: 6763
Read/write check 
product_id
1515966223509088493                              [1.515915625512659e+18]
1515966223509088497                             [1.5159156254510305e+18]
1515966223509088498    [1.5159156254556063e+18, 1.5159156254506296e+1...
1515966223509088499    [1.515915625453577e+18, 1.515915625456618e+18,...
1515966223509088502                             [1.5159156254429404e+18]
                                             ...                        
2273948319141068839      [1.515915625455605e+18, 1.5159156254514947e+18]
2298437344820200326                             [1.5159156254541414e+18]
2298437346070102964                             [1.5159156254449859e+18]
2298437347152233469                             [1.5159156254748726e+18]
2298437347429056895                             [1.5159156254580431e+18]
Name: user_id, Length: 2185, dtype: object
```

## Phase 3 Generate itemsets via dEclat
Write a program GenItemsets that accepts as commandline arguments the name of 
the file generated by Analyze.py, and a min support.  The program uses dEclat, 
with the optimization of first-level Eclat values for supporting transactions.  
Several details:

### namedtuple
You will find several small "classes" needed, e.g. to represent a list of 
IT-pairs.  Native Python is bad at this sort of thing since tuples are 
only numerically indexed and dicts require cumbersome syntax.  Use 
namedtuples for these small structs.

### Implement incrementally
I found it easiest to implement this a step at a time, first setting up the 
parameters for the initial call to dEclat, then implementing the full 
recursion, but just with standard dEclat, then revising to use first-level Eclat.

### Final output
Output a list of namedtuples, each having a set of items and a support for that 
set.  Do this in Pickle format, and as before reread the Pickle file and 
print the result for verification.

## Phase 4 Revise to use Charm
Revise your dEclat implementation to use Charm instead, and to output only 
namedtuples representing closed itemsets. 
  * Return to an Eclat implementation (dEclat is hard to do with Charm)
  * Maintain itemsets as hierarchical lists, as discussed in class.  Any 
  itemset remains its own list, even if added to other itemsets as a sublist 
  of theirs.  This lets you augment an itemset by merging other items, per 
  Charm, and automatically update that itemset within any other itemset 
  to which it belongs.
  * You should need at most a handful of new lines of code added to PHase 3

## Phase 5 Generate association rules
Use the closure sets generated in the prior step to generate meaningful 
association rules: rules that meet a given confidence, lift and leverage. 
Also identify productive itemsets.

Cmmandline arguments will be *pickleFile minConf minLift minLvg*

  * For each itemset, generate all possible association rules, keeping only 
  *nonredundant* rules meeting the criteria.  Save a list of these rules, 
  using an appropriate namedtuple type.  Output this information under 
  each itemset in the confirmatory print.

  * If an itemset is productive (as an entire itemset), label it so in the 
  data and the output print
