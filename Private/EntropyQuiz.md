# Entropy Quiz
<div style="text-align: right">Name ________________________________________</div>

1. 5pts 
We've describe entropy as the expected number of bits to transmit a random result from a probability distribution X.  What if were instead to use lowercase letters a-z to transmit the result, and wanted our entropy value to reflect the expected number of *letters* needed?  Show how you would adjust the entropy equation, and explain why you'd make that adjustment.
```







```
2. 5pts
Consider a probability distribution of 1 or more events that has a binary entropy of H.  I split an event $E_a$ having probability $P_a$ into two events $E_{a1}$ and $E_{a2}$, each with probability $\frac{P_a}{2}$.  What is the highest possible increase in entropy that can result from this split, and what was the prior entropy H in this case?
```









```