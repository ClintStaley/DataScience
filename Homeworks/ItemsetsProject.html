<!doctype html>
<html>
<head>
<meta charset="utf-8">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/4.0.0/github-markdown.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/styles/default.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markdown-it-texmath/css/texmath.min.css">
<link rel="stylesheet" href="file:////home/clint/.vscode/extensions/goessner.mdmath-2.7.4/themes/default/style.css">

</head>
<body class="markdown-body">
<h1 dir="auto" id="itemsets-coding-project">ItemSets Coding Project</h1>
<p dir="auto">This project will produce high-confidence inferences from the per-user itemsets provided
by the electronics-store ks.csv file provided via Canvas.  It has several phases,
roughly reflecting the typical phases of a professional data analysis project.</p>
<h2 dir="auto" id="phase-1-clean-and-organize-the-data">Phase 1 Clean and organize the data</h2>
<h3 dir="auto" id="p1-step-1-plan-the-data-reorganization-due-10p-97">P1 Step 1 Plan the data reorganization (due 10p 9/7)</h3>
<p dir="auto">The provided file does not provide a direct mapping from user id to sets of
purchased product ids by that user.  And not all rows are even useful to an
itemset analysis seeking association rules.</p>
<p dir="auto">A good data science process includes a careful review of the data, and a plan to
&quot;clean&quot; it in appropriate ways.  Review the provided csv files -- you may find
the Orders100.csv an easier starting point.  Determine which rows are actually useful.  (At least two filters are needed to eliminate nonuseful rows).</p>
<p dir="auto">Then, determine what final dataframe structure will best
support a Eclat/dEclat algorithm.  (Consider the three structures in our example database.)</p>
<p dir="auto">Create a subdirectory Itemsets in your repo. Create a short file Analysis.md in that subdirectory summarizing your results.  Submit this md file and the corresponding HTML file to the relevant Canvas assignment for my approval
before proceeding.</p>
<p dir="auto">(Learn MD if you haven't already.  It's an excellent format for Git repository
documentation since it merges well.  Edit your Markdown in VSCode, using
ctl-K V to show a preview and ctl-K , to generate HTML)</p>
<h3 dir="auto" id="p2-step-2-write-the-program-to-produce-your-desired-format">P2 Step 2 Write the program to produce your desired format</h3>
<p dir="auto">Use Pandas to write a program that inputs a given CSV file (first commandline argument)
and prints basic stats on the products, orders and customers.  It then performs
the cleaning and reorganization you planned in the prior step,
producing a Pandas Dataframe as its final product.  It writes the DataFrame to
the specified output file (second commandline argument), and then reads it back
in and prints it, to confirm successful file save.</p>
<p dir="auto">A few important points:</p>
<ul dir="auto">
<li dir="auto">Do not write any loops or if-statements in this code.  Use Pandas Dataframes,
groupBy, etc to do the work.  My implementation is <strong>10 lines long</strong>.  Yours
should be comparably brief.</li>
<li dir="auto">You may choose any file format you like, but be sure it loads and saves quickly with the full dataset.</li>
</ul>
<pre><code dir="auto"><code><div>clint@rifle:~/DataScience/Projects/Sandbox$python3 Analyze.py Orders10000.csv Orders10000.zip
Reading Orders10000.csv
Number of products: 3186
Number of orders: 8260
Number of customers: 6763
Read/write check 
product_id
1515966223509088493                              [1.515915625512659e+18]
1515966223509088497                             [1.5159156254510305e+18]
1515966223509088498    [1.5159156254556063e+18, 1.5159156254506296e+1...
1515966223509088499    [1.515915625453577e+18, 1.515915625456618e+18,...
1515966223509088502                             [1.5159156254429404e+18]
                                             ...                        
2273948319141068839      [1.515915625455605e+18, 1.5159156254514947e+18]
2298437344820200326                             [1.5159156254541414e+18]
2298437346070102964                             [1.5159156254449859e+18]
2298437347152233469                             [1.5159156254748726e+18]
2298437347429056895                             [1.5159156254580431e+18]
Name: user_id, Length: 2185, dtype: object
</div></code></code></pre>
<h2 dir="auto" id="phase-2-generate-itemsets">Phase 2 Generate Itemsets</h2>
<p dir="auto">Write a program GenItemsets that accepts as commandline arguments the name of the file generated by Analyze.py, and a min support.  The program uses dEclat, with the optimization of first-level Eclat values for supporting transactions.  Several details:</p>
<h3 dir="auto" id="namedtuple">namedtuple</h3>
<p dir="auto">You will find several small &quot;classes&quot; needed, e.g. to represent a list of IT-pairs.  Native Python is bad at this sort of thing since tuples are only numerically indexed and dicts require cumbersome syntax.  Prefer namedtuples for these small structs.</p>
<h3 dir="auto" id="implement-in-phases">Implement in phases</h3>
<p dir="auto">I found it easiest to implement this a step at a time, first setting up the parameters for the initial call to dEclat, then implementing the full recursion, but just with standard dEclat, then revising to use first-level Eclat.</p>
<h3 dir="auto" id="final-output">Final output</h3>
<p dir="auto">Output a list of namedtuples, each having a set of items and a support for that set.  Do this in Pickle format, and as before reread the Pickle file and print the result for verification.</p>
<h2 dir="auto" id="phase-3-modify-to-charm-algorithm">Phase 3 Modify to Charm Algorithm.</h2>
<h2 dir="auto" id="phase-4-generate-association-rules">Phase 4 Generate Association Rules</h2>

</body>
</html>